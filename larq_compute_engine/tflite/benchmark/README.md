# Benchmarking TF Lite

## Building the benchmark program

The benchmark program is automatically built with the larq compute engine.
Simply follow the build instructions in the [TF lite readme](../build/README.md).

## Running the benchmark

Simply run
```bash
./benchmark_model.sh benchmarknet.tflite benchmarknet_results.txt
```
which will prompt to ask if `benchmarknet.tflite` should be generated in case it does not yet exist.

The tflite network will be generated by `benchmarknet.py`. Currently it tests the Bconv2d64 op on severaland parameter settings (input size, kernel size, stride, etc). For each setting also the regular Conv2D op is applied for comparison.

When new ops are added in the future, we can add them to `benchmarknet.py` by simply having more input/output pairs in parallel. If this model at some point becomes too large then we can split this into `benchmark_conv2d.py` and other files.

