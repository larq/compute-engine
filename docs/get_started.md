# Get started with Larq Compute Engine
[Larq](https://larq.dev/) toolchain provides all the tools you need to
[train](1.-Choose-a-Larq-Model), [convert](2.-Convert-a-Larq-Model) and
deploy neural networks with extremely low-precision weights and activations,
such as Binarized Neural Networks (BNNs). In this guide, we give you a general
overview of Larq toolchain and provide links to in-depth documentation of
each of the Larq toolchain components.

## 1. Choose a Larq model
To use a BNN model with Larq Compute Engine (LCE), you must convert a Larq
model to a LCE-compatible TenforFlow Lite FlatBuffer.

### Train a Model with Larq


### Use a pre-trained model

## 2. Convert a Larq Model

## 3. Run inference with Larq Compute Engine

### Supported Platforms
- Android
- Raspberry Pi
- Linux

### Load and run a Larq model with C++ API
